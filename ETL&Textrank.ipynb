{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textrank4zh import TextRank4Sentence\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "m1 = spark.read.option(\"multiLine\", True).json(\"hdfs://master/tmp/data_hsu/m1/M1Data_spark.json\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "m1_p = m1.toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_p[\"info\"] = m1_p[\"info\"].apply(lambda x : x.replace(\"\\\\xa0\\\\xa0\",\"\").replace(\"'\",'\"'))\n",
    "\n",
    "import json\n",
    "from json.decoder import JSONDecodeError\n",
    "def good(info):\n",
    "    try:\n",
    "        info = json.loads(info)\n",
    "    except JSONDecodeError:\n",
    "        info = \"bad\"\n",
    "    return info\n",
    "\n",
    "m1_p[\"info\"] = m1_p[\"info\"].apply(good)\n",
    "m1_p = m1_p[m1_p[\"info\"] != \"bad\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def reg_img(imgs):\n",
    "    \n",
    "    result = []\n",
    "    for img in imgs:\n",
    "        if not re.findall(r\"^[https:]+\",img):\n",
    "            img = \"https:\" + img\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        if re.findall(r\"jpg$\",img):\n",
    "            result.append(img)\n",
    "    return result\n",
    "\n",
    "m1_p[\"img_1\"] = m1_p[\"img\"].apply(lambda x : json.loads(x.replace(\"'\",'\"')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_p[\"img\"] = m1_p[\"img_1\"].apply(reg_img)\n",
    "\n",
    "m1_p[\"article_hit\"] = m1_p[\"article_hit\"].apply(lambda x : int(x.replace(\"æ¬¡\",\"\").replace(\",\",\"\")))\n",
    "\n",
    "m1_p = m1_p.drop([\"author\", \"comment\", \"species\", \"img_1\"],axis=1)\n",
    "\n",
    "m1 = spark.createDataFrame(m1_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.rdd.getNumPartitions()\n",
    "m1_new = m1.repartition(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_new.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- article_hit: long (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- href: string (nullable = true)\n",
      " |-- img: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- info: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: long (valueContainsNull = true)\n",
      " |-- phone: long (nullable = true)\n",
      " |-- rate: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m1_new.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textrank\n",
    "```\n",
    "json_schema = ArrayType(StructType([StructField('a', IntegerType(\n",
    "\n",
    "), nullable=False), StructField('b', IntegerType(), nullable=False)]))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "tr4z = TextRank4Sentence()\n",
    "\n",
    "def udf_tr4z(word):\n",
    "    \n",
    "    tr4z.analyze(text=word, lower=True, source=\"all_filters\")\n",
    "    result = []\n",
    "    for setence in tr4z.get_key_sentences(num=3,sentence_min_len=6):\n",
    "        result.append(setence.get(\"sentence\"))\n",
    "    return result\n",
    "\n",
    "udf_tr = udf(udf_tr4z, returnType=ArrayType(StringType()))\n",
    "\n",
    "m1_new = m1_new.withColumn(\"textrank\", udf_tr(m1_new.content))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_new.coalesce(1).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_new.write.format('json').save(\"hdfs://master/tmp/data_hsu/m1/result2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1749"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1_toOne = spark.read.json(\"hdfs://master/tmp/data_hsu/m1/result2/\")\n",
    "m1_toOne.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_toOne = m1_toOne.drop(\"content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_toOne.coalesce(1).write.format('json').save(\"hdfs://master/tmp/data_hsu/m1/result_json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
